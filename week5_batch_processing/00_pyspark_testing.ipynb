{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570f37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1b336",
   "metadata": {},
   "source": [
    "A `SparkSession` is the **class** of the object that we instantiate\n",
    "\n",
    "- This class is the entry point into all functionality in Spark\n",
    "- A `SparkSession` can be used create DataFrames, register DataFrames as tables, execute SQL over tables, cache tables, and read Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7575dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Spark Session, an object that we use to interact with Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7569ec",
   "metadata": {},
   "source": [
    "- The `builder` method is a class attribute used to construct `SparkSession` instances\n",
    "- `master()` sets the Spark master URL to connect to\n",
    "    - `local[*]` means Spark will run on a local cluster (local machine)\n",
    "        - `[*]` means Spark will run with as many CPU cores as possible\n",
    "            - i.e., This tells Spark to use all available cores (e.g., if we wanted to use only 2 cores, we would write `local[2]`)\n",
    "- `appName()` defines the name of our application/session, which will show in the Spark UI at http://localhost:4040/\n",
    "- `getOrCreate()` will create the session or recover the object if it was previously created\n",
    "    - i.e., It returns an existing `SparkSession`, if available, or creates a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7494833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv('./data/taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42262ab4",
   "metadata": {},
   "source": [
    "Note that similarly to pandas, Spark can read CSV files into **DataFrames**, a tabular data structure\n",
    "- But *unlike* pandas, Spark can handle *much bigger* datasets\n",
    "    - However, **it's unable to infer the datatypes of each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e6707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9890c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that writing works to a 'zones' directory\n",
    "df.write.parquet('data/zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70b95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the fhv_tripdata_2019-01.csv file\n",
    "df_fhv = spark.read \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', True) \\\n",
    "    .csv('data/fhv_tripdata_2019-01.csv') # #.csv('data/fhvhv_tripdata_2021-01.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "761d6756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00001|2019-01-01 00:30:00|2019-01-01 02:51:55|        null|        null|   null|                B00001|\n",
      "|              B00001|2019-01-01 00:45:00|2019-01-01 00:54:49|        null|        null|   null|                B00001|\n",
      "|              B00001|2019-01-01 00:15:00|2019-01-01 00:54:52|        null|        null|   null|                B00001|\n",
      "|              B00008|2019-01-01 00:19:00|2019-01-01 00:39:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:27:00|2019-01-01 00:37:00|        null|        null|   null|                B00008|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the FHV data\n",
    "df_fhv.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e10e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that writing works to a 'fhv' directory\n",
    "df_fhv.write.parquet('data/fhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00843ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 08A3-CF2D\n",
      "\n",
      " Directory of C:\\Users\\nimz\\Documents\\de_zoomcamp\\week5_batch_processing\\data\\zones\n",
      "\n",
      "02/23/2024  07:17 PM    <DIR>          .\n",
      "02/23/2024  07:17 PM    <DIR>          ..\n",
      "02/23/2024  07:17 PM                56 .part-00000-88f611ef-406d-4479-b478-72294a039c82-c000.snappy.parquet.crc\n",
      "02/23/2024  07:17 PM                 8 ._SUCCESS.crc\n",
      "02/23/2024  07:17 PM             5,916 part-00000-88f611ef-406d-4479-b478-72294a039c82-c000.snappy.parquet\n",
      "02/23/2024  07:17 PM                 0 _SUCCESS\n",
      "               4 File(s)          5,980 bytes\n",
      "               2 Dir(s)  281,278,066,688 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir data\\zones\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e09aec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 08A3-CF2D\n",
      "\n",
      " Directory of C:\\Users\\nimz\\Documents\\de_zoomcamp\\week5_batch_processing\\data\\fhv\n",
      "\n",
      "02/23/2024  07:23 PM    <DIR>          .\n",
      "02/23/2024  07:23 PM    <DIR>          ..\n",
      "02/23/2024  07:23 PM           176,648 .part-00000-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           181,088 .part-00001-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           182,536 .part-00002-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           179,624 .part-00003-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           167,104 .part-00004-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           179,588 .part-00005-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           176,236 .part-00006-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           171,568 .part-00007-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           175,920 .part-00008-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           177,152 .part-00009-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:22 PM           180,580 .part-00010-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM           179,160 .part-00011-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet.crc\n",
      "02/23/2024  07:23 PM                 8 ._SUCCESS.crc\n",
      "02/23/2024  07:23 PM        22,609,840 part-00000-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        23,177,799 part-00001-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        23,363,285 part-00002-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        22,990,689 part-00003-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        21,387,953 part-00004-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        22,985,934 part-00005-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        22,556,909 part-00006-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        21,959,676 part-00007-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        22,516,454 part-00008-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        22,674,129 part-00009-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:22 PM        23,112,810 part-00010-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM        22,931,070 part-00011-3fe1b419-cc5e-4d57-bdf3-8336fbe2d5b7-c000.snappy.parquet\n",
      "02/23/2024  07:23 PM                 0 _SUCCESS\n",
      "              26 File(s)    274,393,760 bytes\n",
      "               2 Dir(s)  281,266,577,408 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir data\\fhv\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd906e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00001', pickup_datetime=datetime.datetime(2019, 1, 1, 0, 30), dropOff_datetime=datetime.datetime(2019, 1, 1, 2, 51, 55), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00001'),\n",
       " Row(dispatching_base_num='B00001', pickup_datetime=datetime.datetime(2019, 1, 1, 0, 45), dropOff_datetime=datetime.datetime(2019, 1, 1, 0, 54, 49), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00001'),\n",
       " Row(dispatching_base_num='B00001', pickup_datetime=datetime.datetime(2019, 1, 1, 0, 15), dropOff_datetime=datetime.datetime(2019, 1, 1, 0, 54, 52), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00001'),\n",
       " Row(dispatching_base_num='B00008', pickup_datetime=datetime.datetime(2019, 1, 1, 0, 19), dropOff_datetime=datetime.datetime(2019, 1, 1, 0, 39), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00008'),\n",
       " Row(dispatching_base_num='B00008', pickup_datetime=datetime.datetime(2019, 1, 1, 0, 27), dropOff_datetime=datetime.datetime(2019, 1, 1, 0, 37), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00008')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f8351",
   "metadata": {},
   "source": [
    "**Note that Spark may be unable to infer data types of columns, say our `datetime` columns here might by strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afab2d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropOff_datetime', TimestampType(), True), StructField('PUlocationID', IntegerType(), True), StructField('DOlocationID', IntegerType(), True), StructField('SR_Flag', IntegerType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091624bd",
   "metadata": {},
   "source": [
    "But it worked this time\n",
    "\n",
    "Check the zones data too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0b121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR'),\n",
       " Row(LocationID='2', Borough='Queens', Zone='Jamaica Bay', service_zone='Boro Zone'),\n",
       " Row(LocationID='3', Borough='Bronx', Zone='Allerton/Pelham Gardens', service_zone='Boro Zone'),\n",
       " Row(LocationID='4', Borough='Manhattan', Zone='Alphabet City', service_zone='Yellow Zone'),\n",
       " Row(LocationID='5', Borough='Staten Island', Zone='Arden Heights', service_zone='Boro Zone')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "389f4575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', StringType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-zoom]",
   "language": "python",
   "name": "conda-env-.conda-zoom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
